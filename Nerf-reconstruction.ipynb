{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257860de-71ad-4386-88bd-fc945e3bc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import get_rays\n",
    "from rendering import rendering\n",
    "from model import Voxels, Nerf\n",
    "from ml_helpers import training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5922e325-8976-4a36-88aa-908cbe4d3953",
   "metadata": {},
   "source": [
    "# Camera / Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e62ab8-9524-48b6-a646-01b27c9a3fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 400, 400, 4)\n",
      "(10, 400, 400, 4)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "o, d, target_px_values = get_rays('fox', mode='train')\n",
    "dataloader = DataLoader(torch.cat((torch.from_numpy(o).reshape(-1, 3).type(torch.float),\n",
    "                                   torch.from_numpy(d).reshape(-1, 3).type(torch.float),\n",
    "                                   torch.from_numpy(target_px_values).reshape(-1, 3).type(torch.float)), dim=1),\n",
    "                       batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "dataloader_warmup = DataLoader(torch.cat((torch.from_numpy(o).reshape(90, 400, 400, 3)[:, 100:300, 100:300, :].reshape(-1, 3).type(torch.float),\n",
    "                               torch.from_numpy(d).reshape(90, 400, 400, 3)[:, 100:300, 100:300, :].reshape(-1, 3).type(torch.float),\n",
    "                               torch.from_numpy(target_px_values).reshape(90, 400, 400, 3)[:, 100:300, 100:300, :].reshape(-1, 3).type(torch.float)), dim=1),\n",
    "                       batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_o, test_d, test_target_px_values = get_rays('fox', mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcc6284-ff38-4a9d-a914-7cd8ff9163fb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd96eec-e258-469d-8781-da1dc2bd1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "\n",
    "tn = 8.\n",
    "tf = 12.\n",
    "nb_epochs = 10\n",
    "lr = 1e-3\n",
    "gamma = .5\n",
    "nb_bins = 100\n",
    "\n",
    "model = Nerf(hidden_dim=128).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10], gamma=gamma)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2014548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = training(model, optimizer, scheduler, tn, tf, nb_bins, 1, dataloader_warmup, device=device)\n",
    "plt.plot(training_loss)\n",
    "plt.show()\n",
    "training_loss = training(model, optimizer, scheduler, tn, tf, nb_bins, nb_epochs, dataloader, device=device)\n",
    "plt.plot(training_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07909aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nerf(\n",
       "  (block1): Sequential(\n",
       "    (0): Linear(in_features=63, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (9): ReLU()\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Linear(in_features=191, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=129, bias=True)\n",
       "  )\n",
       "  (rgb_head): Sequential(\n",
       "    (0): Linear(in_features=155, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=3, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"model\",map_location=torch.device('mps'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dec7f39",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 4.83 GB, other allocations: 4.11 GB, max allowed: 9.07 GB). Tried to allocate 183.11 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img \u001b[39m=\u001b[39m rendering(model, torch\u001b[39m.\u001b[39;49mfrom_numpy(o[\u001b[39m3\u001b[39;49m])\u001b[39m.\u001b[39;49mto(torch\u001b[39m.\u001b[39;49mfloat32)\u001b[39m.\u001b[39;49mto(device), torch\u001b[39m.\u001b[39;49mfrom_numpy(d[\u001b[39m3\u001b[39;49m])\u001b[39m.\u001b[39;49mto(torch\u001b[39m.\u001b[39;49mfloat32)\u001b[39m.\u001b[39;49mto(device), \n\u001b[1;32m      2\u001b[0m                 tn, tf, nb_bins\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[0;32m~/Developer/udemy-nerf/rendering.py:15\u001b[0m, in \u001b[0;36mrendering\u001b[0;34m(model, rays_o, rays_d, tn, tf, nb_bins, device, white_bckgr)\u001b[0m\n\u001b[1;32m     11\u001b[0m delta \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((t[\u001b[39m1\u001b[39m:] \u001b[39m-\u001b[39m t[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], torch\u001b[39m.\u001b[39mtensor([\u001b[39m1e10\u001b[39m], device\u001b[39m=\u001b[39mdevice)))\n\u001b[1;32m     13\u001b[0m x \u001b[39m=\u001b[39m rays_o\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m t\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m rays_d\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m) \u001b[39m# [nb_rays, nb_bins, 3]    \u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m colors, density \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mintersect(x\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m), rays_d\u001b[39m.\u001b[39;49mexpand(x\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], x\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], \u001b[39m3\u001b[39;49m)\u001b[39m.\u001b[39;49mtranspose(\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m))\n\u001b[1;32m     17\u001b[0m colors \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mreshape((x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], nb_bins, \u001b[39m3\u001b[39m)) \u001b[39m# [nb_rays, nb_bins, 3]\u001b[39;00m\n\u001b[1;32m     18\u001b[0m density \u001b[39m=\u001b[39m density\u001b[39m.\u001b[39mreshape((x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], nb_bins))\n",
      "File \u001b[0;32m~/Developer/udemy-nerf/model.py:86\u001b[0m, in \u001b[0;36mNerf.intersect\u001b[0;34m(self, x, d)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mintersect\u001b[39m(\u001b[39mself\u001b[39m, x, d):\n\u001b[0;32m---> 86\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(x, d)\n",
      "File \u001b[0;32m~/Developer/udemy-nerf/model.py:74\u001b[0m, in \u001b[0;36mNerf.forward\u001b[0;34m(self, xyz, d)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, xyz, d):\n\u001b[1;32m     73\u001b[0m     x_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_encoding(xyz, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLpos) \u001b[39m# [batch_size, Lpos * 6 + 3]\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     d_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpositional_encoding(d, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mLdir) \u001b[39m# [batch_size, Ldir * 6 + 3]\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock1(x_emb) \u001b[39m# [batch_size, hidden_dim]\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock2(torch\u001b[39m.\u001b[39mcat((h, x_emb), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)) \u001b[39m# [batch_size, hidden_dim + 1]\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/udemy-nerf/model.py:65\u001b[0m, in \u001b[0;36mNerf.positional_encoding\u001b[0;34m(self, x, L)\u001b[0m\n\u001b[1;32m     63\u001b[0m out \u001b[39m=\u001b[39m [x]\n\u001b[1;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(L):\n\u001b[0;32m---> 65\u001b[0m     out\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39msin(\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m j \u001b[39m*\u001b[39;49m x))\n\u001b[1;32m     66\u001b[0m     out\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mcos(\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m j \u001b[39m*\u001b[39m x))\n\u001b[1;32m     67\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(out, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 4.83 GB, other allocations: 4.11 GB, max allowed: 9.07 GB). Tried to allocate 183.11 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "img = rendering(model, torch.from_numpy(o[3]).to(torch.float32).to(device), torch.from_numpy(d[3]).to(torch.float32).to(device), \n",
    "                tn, tf, nb_bins=100, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d714b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a964464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img.reshape(400, 400, 3).data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b2ceae-86b6-4d6d-aafe-ac3627807f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_nerf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8850e856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
